# Efficient Data Storage for Faster Model Predictions

![Two data scientists working on a dashboard.](hr-image-small.png)

## Project Overview
This project focuses on cleaning and optimizing a large customer dataset from a fictional online data science training provider Radar DataCamp. The dataset, `customer_train.csv`, contains anonymized student information and their job-seeking status during training. The goal is to efficiently store the dataset for faster model predictions.

## Key Tasks
1. **Exploratory Data Analysis**: Understand the dataset.
2. **Converting Column Types**: Optimize memory usage.
3. **Collapsing Factor Levels**: Reduce redundant information.
4. **Reordering Columns**: Match the original dataset.
5. **Filtering the Dataset**: Select students with specific experience and company size criteria.

## Technologies Used
- Python
- Pandas

## Dataset Information
- `customer_train.csv` contains columns such as `student_id`, `city`, `gender`, `relevant_experience`, `education_level`, `experience`, `company_size`, and more.

## Getting Started
1. Clone this repository.
2. Install the required dependencies (`pandas`).
3. Run the provided Python script to clean and optimize the dataset.

## Conclusion
Efficiently storing large datasets is crucial for ensuring that models can generate predictions in a reasonable time frame. This project provides a proof-of-concept for optimizing the storage of a customer dataset, which can be applied to other datasets in the future.
